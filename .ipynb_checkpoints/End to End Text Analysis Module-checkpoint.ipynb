{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "from colorlog import ColoredFormatter\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')  \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b16daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_files_in_folder(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.txt'): \n",
    "                print(file_name)\n",
    "                print()\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                        words = content.split() \n",
    "                        print(len(words))\n",
    "                        StopWords.extend(words)  # Append words to the StopWords list\n",
    "                except UnicodeDecodeError:\n",
    "                    print(\"Could not process\" , file_name)\n",
    "                    print(f\"UnicodeDecodeError: Could not decode {file_path} using 'utf-8' encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"StopWords/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PositiveWords = \"\"\n",
    "with open(\"MasterDictionary/positive-words.txt\", 'r') as file:\n",
    "            PositiveWords = file.read()\n",
    "        \n",
    "PositiveWords = re.findall(r'\\b\\w+\\b', PositiveWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "PositiveWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c347ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NegativeWords = \"\"\n",
    "with open(\"MasterDictionary/negative-words.txt\", 'r' , encoding = 'latin-1') as file:\n",
    "            NegativeWords = file.read()\n",
    "        \n",
    "NegativeWords = re.findall(r'\\b\\w+\\b', NegativeWords)\n",
    "# Remove all numbers\n",
    "NegativeWords = [x for x in NegativeWords if not x.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb10fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalysis:\n",
    "    text = \"\"\n",
    "    words = []\n",
    "    PositiveWords = []\n",
    "    StopWords = []\n",
    "    \n",
    "    def __init__(self , text , PositiveWords , NegativeWords , StopWords):\n",
    "        self.text =  text\n",
    "        self.words = re.findall(r'\\w+\\b' , text)\n",
    "        self.PositiveWords = PositiveWords\n",
    "        self.NegativeWords = NegativeWords\n",
    "        self.StopWords = StopWords\n",
    "    \n",
    "    def Positive_Score(self):\n",
    "        positive_words_count = 0\n",
    "        stopwords_count = 0\n",
    "        Total_Words = len(self.words)\n",
    "        \n",
    "        print(f\"Total Words to Process: {Total_Words}\")\n",
    "        \n",
    "        for word in self.words:\n",
    "            # word should not be a stopword\n",
    "            if word in self.StopWords:\n",
    "                print(\"Stopword: \", word)\n",
    "                stopwords_count += 1\n",
    "                continue\n",
    "            \n",
    "            if word in self.PositiveWords:\n",
    "                print(\"Positive Word: \", word)\n",
    "                positive_words_count += 1\n",
    "            else:\n",
    "                print(\"Normal Word: \", word)\n",
    "        \n",
    "        print()\n",
    "        print(f\"Positive words found: {positive_words_count}\")\n",
    "        print(f\"StopWords words found: {stopwords_count}\")\n",
    "        print(f\"Total Words: {Total_Words}\")\n",
    "        \n",
    "        \n",
    "        positive_percentage = (positive_words_count / Total_Words) * 100\n",
    "        print(f\"Positive words percentage: {positive_percentage}%\")\n",
    "        \n",
    "        positive_percentage = \"{:.2f}\".format(positive_percentage)\n",
    "        return positive_percentage\n",
    "        \n",
    "    \n",
    "    def Negative_Score(self):\n",
    "        negative_words_count = 0\n",
    "        stopwords_count = 0\n",
    "        Total_Words = len(self.words)\n",
    "        \n",
    "        print(f\"Total Words to Process: {Total_Words}\")\n",
    "        \n",
    "        for word in self.words:\n",
    "            # word should not be a stopword\n",
    "            if word in self.StopWords:\n",
    "                print(\"Stopword: \", word)\n",
    "                stopwords_count += 1\n",
    "                continue\n",
    "            \n",
    "            if word in self.NegativeWords:\n",
    "                print(\"Negative Word: \", word)\n",
    "                negative_words_count += 1\n",
    "            else:\n",
    "                print(\"Normal Word: \", word)\n",
    "        \n",
    "        print()\n",
    "        print(f\"Negative words found: {negative_words_count}\")\n",
    "        print(f\"StopWords words found: {stopwords_count}\")\n",
    "        print(f\"Total Words: {Total_Words}\")\n",
    "        \n",
    "        \n",
    "        negative_percentage = (negative_words_count / Total_Words) * 100\n",
    "        print(f\"Positive words percentage: {negative_percentage}%\")\n",
    "        \n",
    "        negative_percentage = \"{:.2f}\".format(negative_percentage)\n",
    "        return negative_percentage\n",
    "\n",
    "    \n",
    "    def Polarity_Score(self):\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        return sia.polarity_scores(self.text)\n",
    "    \n",
    "    def Subjectivity_Score(self):\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        scores = sid.polarity_scores(self.text)\n",
    "        subjectivity_score = scores['compound']\n",
    "        return subjectivity_score\n",
    "    \n",
    "    def AvgSentence_Length(self):\n",
    "        curr_length = 0\n",
    "        arr = []\n",
    "\n",
    "        for char in text:\n",
    "            if(char == '.'):\n",
    "                arr.append(curr_length)\n",
    "                curr_length = 0\n",
    "            else:\n",
    "                curr_length += 1\n",
    "        \n",
    "        arr.append(curr_length)\n",
    "        \n",
    "        sum = 0\n",
    "        for length in arr:\n",
    "            print(length , end = \" \")\n",
    "            sum += length\n",
    "        print()\n",
    "        \n",
    "        return sum / len(arr)\n",
    "    \n",
    "    def Percentage_Complex_Words(self):\n",
    "        complex_word_count = self.Complex_Word_Count(False)\n",
    "        Total_Words = len(self.words)\n",
    "        \n",
    "        return ((complex_word_count) / Total_Words) * 100\n",
    "    \n",
    "    def Fog_Index(self):\n",
    "        word_count = len(self.words)\n",
    "        def num_sentences(text):\n",
    "            full_stop_count = 0\n",
    "            for character in text:\n",
    "                if(character == '.'):\n",
    "                    full_stop_count += 1\n",
    "            \n",
    "            return full_stop_count + 1\n",
    "        sentence_count = num_sentences(self.text)\n",
    "        complex_words_count = self.Complex_Word_Count(False)\n",
    "        \n",
    "        \n",
    "        print(\"Formula: \")\n",
    "        print('''\n",
    "            FogIndex= 0.4 * ((word_count / sentence_count) + 100 * (complex_words_count / word_count))\n",
    "        ''')\n",
    "        \n",
    "        return 0.4 * ((word_count / sentence_count) + 100 * (complex_words_count / word_count))\n",
    "            \n",
    "    \n",
    "    def Avg_Words_Per_Sentence(self):\n",
    "\n",
    "        words_in_sentence = []\n",
    "        curr_word_count = 0\n",
    "        curr_word = \"\"\n",
    "\n",
    "        for char in text:\n",
    "            # '.' => move to the next word\n",
    "            if(char == '.'):\n",
    "                curr_word_count += 1\n",
    "                words_in_sentence.append(curr_word_count)\n",
    "                curr_word_count = 0\n",
    "                curr_word = \"\"\n",
    "            # current word ends\n",
    "            elif(char == ' '):\n",
    "                curr_word_count += 1\n",
    "                curr_word = \"\"\n",
    "        \n",
    "            # ad the character to the current word\n",
    "            else:\n",
    "                curr_word += char\n",
    "        \n",
    "        words_in_sentence.append(curr_word_count)\n",
    "        \n",
    "        sum = 0\n",
    "        for word_count in words_in_sentence:\n",
    "            print(word_count , end = \" \")\n",
    "            sum += word_count\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        return sum / len(words_in_sentence)\n",
    "    \n",
    "    def Complex_Word_Count(self , logs = True):\n",
    "        def is_complex_word(word):\n",
    "            # Get part-of-speech tags for the word\n",
    "            tagged = nltk.pos_tag([word])  \n",
    "            pos = tagged[0][1]\n",
    "            # Check if the word has certain parts of speech that might indicate complexity      \n",
    "            return pos.startswith('JJ') or pos.startswith('NN') or pos.startswith('VB')  # Checking for adjectives, nouns, or verbs\n",
    "\n",
    "        complex_word_count = 0\n",
    "        for word in self.words:\n",
    "            if(is_complex_word(word)):\n",
    "                complex_word_count += 1\n",
    "                \n",
    "                if(logs):\n",
    "                    print(\"Complex Word:\" , word)\n",
    "        \n",
    "        print(\"Total Words:\" , len(self.words))\n",
    "        print(\"Complex Words: \" , complex_word_count)\n",
    "        \n",
    "        return complex_word_count\n",
    "\n",
    "    \n",
    "    def Word_Count(self):\n",
    "        return len(self.words)\n",
    "    \n",
    "    def Syllable_Per_Word(self):\n",
    "        d = cmudict.dict()\n",
    "        def count_syllables(word):\n",
    "            if word.lower() in d:\n",
    "                return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "            else:\n",
    "                # If word is not found in the dictionary, provide an alternate solution\n",
    "                # This might not be completely accurate for all words\n",
    "            \n",
    "                return max([len([y for y in x if y[-1].isdigit()]) for x in d if x.lower().startswith(word.lower())], default=1)\n",
    "        \n",
    "        sum = 0\n",
    "        count = 0\n",
    "        for word in self.words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            sum += syllable_count\n",
    "            \n",
    "            print(word ,\":\" , syllable_count)\n",
    "            count += 1\n",
    "        \n",
    "        return ceil(sum / count)\n",
    "    \n",
    "    def Personal_Pronouns():\n",
    "        pass\n",
    "    \n",
    "    def Avg_Word_Length(self):\n",
    "        sum_of_characters = 0\n",
    "        for word in self.words:\n",
    "            print(word , len(word))\n",
    "            sum_of_characters += len(word)\n",
    "            \n",
    "        print(\"Sum of Characters: \" , sum_of_characters)\n",
    "        print(\"Number of Words: \" , len(self.words) )\n",
    "        return sum_of_characters//len(self.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"text_files/text_file-0\",'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea881d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA = TextAnalysis(text , PositiveWords , NegativeWords , StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Positive_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Negative_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Avg_Word_Length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bce2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Avg_Words_Per_Sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Complex_Word_Count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7785530",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Polarity_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Percentage_Complex_Words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Fog_Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3950eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Avg_Words_Per_Sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.AvgSentence_Length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA.Syllable_Per_Word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c6a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
